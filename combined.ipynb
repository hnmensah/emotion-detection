{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "nBdU-hd-05mh",
    "outputId": "714c55f8-3081-4a35-9848-d3b4dbd69c5a"
   },
   "outputs": [],
   "source": [
    "# mount google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "88JmDwQj0xSz",
    "outputId": "8d3b2eda-1322-4793-ba76-c8a15718a5b4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Flatten, Input, Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling2D, MaxPooling1D, Dense, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "# download from:\n",
    "# https://github.com/SenticNet/MELD/blob/master/baseline/baseline.py\n",
    "\n",
    "# DATA_PATH = '/content/gdrive/Team Drives/IKE Data/Emotion detection'\n",
    "DATA_PATH = 'data'\n",
    "DATASET_PATH = os.path.join(DATA_PATH, 'dataset_combined.pkl')\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, 'emorynlp_train_final.csv'))\n",
    "val = pd.read_csv(os.path.join(DATA_PATH, 'emorynlp_dev_final.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'emorynlp_test_final.csv'))\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer and fit on train\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(train['Utterance'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join('data', 'glove.6B', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKbVbBe60xS4",
    "outputId": "1e463774-2981-48ba-837b-f18ed726909e"
   },
   "outputs": [],
   "source": [
    "def preprocess(data, folder, tokenizer):\n",
    "    data['label'] = data['Emotion'].astype('category').cat.codes\n",
    "\n",
    "    labels = []\n",
    "    spectrums = []\n",
    "    texts = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        filename = 'sea%d_ep%d_sc%d_utt%d.wav' % (row.Season, row.Episode, row.Scene_ID, row.Utterance_ID)\n",
    "        path = os.path.join('data', 'audio', folder, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            print('file does not exist', path)\n",
    "            continue\n",
    "\n",
    "        sample, sr = librosa.load(path, 24000, duration=2)\n",
    "        assert sr == 24000, 'sample rate incorrect'\n",
    "\n",
    "        padded_sample = np.zeros(48001, dtype='float32')\n",
    "        padded_sample[:sample.shape[0]] = sample\n",
    "\n",
    "        melgram = librosa.feature.melspectrogram(padded_sample, sr, n_fft=512, hop_length=256, n_mels=96)\n",
    "        log_melgram = librosa.amplitude_to_db(melgram)\n",
    "        log_melgram = np.expand_dims(log_melgram, axis=-1)\n",
    "        assert log_melgram.shape == (96, 188, 1), 'mel shape incorrect'\n",
    "\n",
    "        labels.append(row.label)\n",
    "        spectrums.append(log_melgram)\n",
    "        texts.append(row['Utterance'])\n",
    "\n",
    "        if index % 500 == 0:\n",
    "            print('loaded %d from %d rows' % (index, len(data)))\n",
    "        \n",
    "    # create np array for audio\n",
    "    x1 = np.stack(spectrums)\n",
    "    \n",
    "    # create np array for texts\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=33)\n",
    "    x2 = np.stack(padded)\n",
    "    \n",
    "    # create np array for labels\n",
    "    y = np.stack(labels)\n",
    "    y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "    \n",
    "    # shuffle\n",
    "    x1, x2, y = shuffle(x1, x2, y, random_state=42)\n",
    "    \n",
    "    return [x1, x2], y\n",
    "\n",
    "if not os.path.isfile(DATASET_PATH):\n",
    "    print(\"loading from cache\")\n",
    "    with open(DATASET_PATH, 'rb') as handle:\n",
    "        train_x, train_y, test_x, test_y, val_x, val_y, word_index = pickle.load(handle)\n",
    "\n",
    "else:        \n",
    "    train_x, train_y = preprocess(train, 'train', tokenizer)\n",
    "    test_x, test_y = preprocess(test, 'test', tokenizer)\n",
    "    val_x, val_y = preprocess(val, 'dev', tokenizer)\n",
    "    with open(DATASET_PATH, 'wb') as handle:\n",
    "        pickle.dump((train_x, train_y, test_x, test_y, val_x, val_y, word_index), handle)    \n",
    "\n",
    "print(train_x[0].shape, train_x[1].shape, train_y.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2637
    },
    "colab_type": "code",
    "id": "YLLqGOxg0xS_",
    "outputId": "0d654a5d-4ee5-4f8a-e0df-0073b8f0acbe"
   },
   "outputs": [],
   "source": [
    "# show some spectrograms\n",
    "for i in range(0, 10):\n",
    "    plt.imshow(np.squeeze(train_x[0][i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding matrix from glove\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('data', 'glove.6B', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = list(train_x)\n",
    "val_x = list(val_x)\n",
    "test_x = list(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_x[0].shape, train_x[1].shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.keras import BalancedBatchGenerator\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "train_gen = BalancedBatchGenerator(\n",
    "    train_x[0], train_y, sampler=NearMiss(), batch_size=32, random_state=42)\n",
    "\n",
    "x, y = next(train_gen)\n",
    "print (x[0].shape, x[1].shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "DWkp6RWt0xTC",
    "outputId": "20c18441-9769-4a96-e70c-a63a3422dd4a"
   },
   "outputs": [],
   "source": [
    "# audio layers\n",
    "audio_input = Input(shape=train_x[0].shape[1:])\n",
    "\n",
    "x = Conv2D(32, 5, activation='relu')(audio_input)\n",
    "x = MaxPooling2D(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling2D(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "audio_output = Dropout(0.2)(x)\n",
    "\n",
    "# text layers\n",
    "text_input = Input(shape=(33,), dtype='int32')\n",
    "\n",
    "x = Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], input_length=33, trainable=False)(text_input)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "text_output = Dropout(0.3)(x)\n",
    "\n",
    "# final prediction layers\n",
    "x = Concatenate()([audio_output, text_output])\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model([audio_input, text_input], x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=20, verbose=1)\n",
    "print(\"Accuracy: %.2f\" % model.evaluate(test_x), test_y)[1])\n",
    "\n",
    "# base: 0.3417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "audio.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:event-acoustics]",
   "language": "python",
   "name": "conda-env-event-acoustics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
