{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Scene_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What you guys don't understand is, for us, kis...</td>\n",
       "      <td>['Monica Geller']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:02.877</td>\n",
       "      <td>00:00:07.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, right!.......Y'serious?</td>\n",
       "      <td>['Joey Tribbiani']</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:04.504</td>\n",
       "      <td>00:00:07.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh, yeah!</td>\n",
       "      <td>['Phoebe Buffay']</td>\n",
       "      <td>Joyful</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:07.924</td>\n",
       "      <td>00:00:09.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everything you need to know is in that first k...</td>\n",
       "      <td>['Rachel Green']</td>\n",
       "      <td>Powerful</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:11.970</td>\n",
       "      <td>00:00:17.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely.</td>\n",
       "      <td>['Monica Geller']</td>\n",
       "      <td>Powerful</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:14.139</td>\n",
       "      <td>00:00:15.097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance             Speaker  \\\n",
       "0  What you guys don't understand is, for us, kis...   ['Monica Geller']   \n",
       "1                      Yeah, right!.......Y'serious?  ['Joey Tribbiani']   \n",
       "2                                          Oh, yeah!   ['Phoebe Buffay']   \n",
       "3  Everything you need to know is in that first k...    ['Rachel Green']   \n",
       "4                                        Absolutely.   ['Monica Geller']   \n",
       "\n",
       "    Emotion  Scene_ID  Utterance_ID  Season  Episode    Start_Time  \\\n",
       "0    Joyful         1             1       1        2  00:00:02.877   \n",
       "1   Neutral         1             2       1        2  00:00:04.504   \n",
       "2    Joyful         1             3       1        2  00:00:07.924   \n",
       "3  Powerful         1             4       1        2  00:00:11.970   \n",
       "4  Powerful         1             5       1        2  00:00:14.139   \n",
       "\n",
       "       End_Time  \n",
       "0  00:00:07.548  \n",
       "1  00:00:07.548  \n",
       "2  00:00:09.508  \n",
       "3  00:00:17.683  \n",
       "4  00:00:15.097  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Flatten, Input, Conv1D, MaxPooling1D, Dense, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import librosa\n",
    "\n",
    "# data from:\n",
    "# https://github.com/SenticNet/MELD/blob/master/baseline/baseline.py\n",
    "\n",
    "train = pd.read_csv(os.path.join('data', 'emorynlp_train_final.csv'))\n",
    "val = pd.read_csv(os.path.join('data', 'emorynlp_dev_final.csv'))\n",
    "test = pd.read_csv(os.path.join('data', 'emorynlp_test_final.csv'))\n",
    "# train = train.sample(frac=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['Emotion'].astype('category').cat.codes\n",
    "# n_classes = labels.max() + 1\n",
    "# labels = to_categorical(labels)\n",
    "# labels, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 0 from 7551 rows\n",
      "loaded 100 from 7551 rows\n",
      "loaded 200 from 7551 rows\n",
      "loaded 300 from 7551 rows\n",
      "loaded 400 from 7551 rows\n",
      "loaded 500 from 7551 rows\n",
      "loaded 600 from 7551 rows\n",
      "loaded 700 from 7551 rows\n",
      "loaded 800 from 7551 rows\n",
      "loaded 900 from 7551 rows\n",
      "loaded 1000 from 7551 rows\n",
      "loaded 1100 from 7551 rows\n",
      "loaded 1200 from 7551 rows\n",
      "loaded 1300 from 7551 rows\n",
      "loaded 1400 from 7551 rows\n",
      "loaded 1500 from 7551 rows\n",
      "loaded 1600 from 7551 rows\n",
      "loaded 1700 from 7551 rows\n",
      "loaded 1800 from 7551 rows\n",
      "loaded 1900 from 7551 rows\n",
      "loaded 2000 from 7551 rows\n",
      "loaded 2100 from 7551 rows\n",
      "loaded 2200 from 7551 rows\n",
      "loaded 2300 from 7551 rows\n",
      "loaded 2400 from 7551 rows\n",
      "loaded 2500 from 7551 rows\n",
      "loaded 2600 from 7551 rows\n",
      "loaded 2700 from 7551 rows\n",
      "loaded 2800 from 7551 rows\n",
      "loaded 2900 from 7551 rows\n",
      "loaded 3000 from 7551 rows\n",
      "loaded 3100 from 7551 rows\n",
      "loaded 3200 from 7551 rows\n",
      "loaded 3300 from 7551 rows\n",
      "loaded 3400 from 7551 rows\n",
      "loaded 3500 from 7551 rows\n",
      "loaded 3600 from 7551 rows\n",
      "loaded 3700 from 7551 rows\n",
      "loaded 3800 from 7551 rows\n",
      "loaded 3900 from 7551 rows\n",
      "loaded 4000 from 7551 rows\n",
      "loaded 4100 from 7551 rows\n",
      "loaded 4200 from 7551 rows\n",
      "loaded 4300 from 7551 rows\n",
      "loaded 4400 from 7551 rows\n",
      "loaded 4500 from 7551 rows\n",
      "loaded 4600 from 7551 rows\n",
      "loaded 4700 from 7551 rows\n",
      "loaded 4800 from 7551 rows\n",
      "loaded 4900 from 7551 rows\n",
      "loaded 5000 from 7551 rows\n",
      "loaded 5100 from 7551 rows\n",
      "loaded 5200 from 7551 rows\n",
      "loaded 5300 from 7551 rows\n",
      "loaded 5400 from 7551 rows\n",
      "loaded 5500 from 7551 rows\n",
      "loaded 5600 from 7551 rows\n",
      "loaded 5700 from 7551 rows\n",
      "loaded 5800 from 7551 rows\n",
      "loaded 5900 from 7551 rows\n",
      "loaded 6000 from 7551 rows\n",
      "loaded 6100 from 7551 rows\n",
      "loaded 6200 from 7551 rows\n",
      "file does not exist data/audio/train/sea4_ep4_sc3_utt8.wav\n",
      "file does not exist data/audio/train/sea4_ep4_sc3_utt9.wav\n",
      "file does not exist data/audio/train/sea4_ep4_sc3_utt10.wav\n",
      "loaded 6300 from 7551 rows\n",
      "loaded 6400 from 7551 rows\n",
      "loaded 6500 from 7551 rows\n",
      "loaded 6600 from 7551 rows\n",
      "loaded 6700 from 7551 rows\n",
      "loaded 6800 from 7551 rows\n",
      "loaded 6900 from 7551 rows\n",
      "loaded 7000 from 7551 rows\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "spectrums = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    filename = 'sea%d_ep%d_sc%d_utt%d.wav' % (row.Season, row.Episode, row.Scene_ID, row.Utterance_ID)\n",
    "    path = os.path.join('data', 'audio', 'train', filename)\n",
    "    if not os.path.isfile(path):\n",
    "        print('file does not exist', path)\n",
    "        continue\n",
    "\n",
    "    sample, sr = librosa.load(path, 24000, duration=2)\n",
    "    assert sr == 24000, 'sample rate incorrect'\n",
    "    \n",
    "    padded_sample = np.zeros(48001, dtype='float32')\n",
    "    padded_sample[:sample.shape[0]] = sample\n",
    "            \n",
    "    melgram = librosa.feature.melspectrogram(padded_sample, sr, n_fft=512, hop_length=256, n_mels=96)\n",
    "    log_melgram = librosa.amplitude_to_db(melgram)\n",
    "    log_melgram = np.expand_dims(log_melgram, axis=-1)\n",
    "    assert log_melgram.shape == (96, 188, 1)\n",
    "    \n",
    "    labels.append(row.label)\n",
    "    spectrums.append(log_melgram)\n",
    "    \n",
    "    if index % 100 == 0:\n",
    "        print('loaded %d from %d rows' % (index, len(train)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x = np.stack(spectrums)\n",
    "y = np.stack(labels)\n",
    "# shuffle\n",
    "train_x, train_y = shuffle(x, y)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, 5, activation='relu')(model_input)\n",
    "x = MaxPooling2D(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling2D(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(model_input, x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=20, verbose=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:event-acoustics]",
   "language": "python",
   "name": "conda-env-event-acoustics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
