{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "nBdU-hd-05mh",
    "outputId": "714c55f8-3081-4a35-9848-d3b4dbd69c5a"
   },
   "outputs": [],
   "source": [
    "# mount google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "88JmDwQj0xSz",
    "outputId": "8d3b2eda-1322-4793-ba76-c8a15718a5b4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Flatten, Input, Conv1D, Conv2D, MaxPooling2D, GlobalMaxPooling2D, MaxPooling1D, Dense, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "# download from:\n",
    "# https://github.com/SenticNet/MELD/blob/master/baseline/baseline.py\n",
    "\n",
    "# DATA_PATH = '/content/gdrive/Team Drives/IKE Data/Emotion detection'\n",
    "DATA_PATH = 'data'\n",
    "DATASET_PATH = os.path.join(DATA_PATH, 'dataset.pkl')\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, 'emorynlp_train_final.csv'))\n",
    "val = pd.read_csv(os.path.join(DATA_PATH, 'emorynlp_dev_final.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'emorynlp_test_final.csv'))\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKbVbBe60xS4",
    "outputId": "1e463774-2981-48ba-837b-f18ed726909e"
   },
   "outputs": [],
   "source": [
    "def preprocess(data, folder):\n",
    "    data['label'] = data['Emotion'].astype('category').cat.codes\n",
    "\n",
    "    labels = []\n",
    "    spectrums = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        filename = 'sea%d_ep%d_sc%d_utt%d.wav' % (row.Season, row.Episode, row.Scene_ID, row.Utterance_ID)\n",
    "        path = os.path.join('data', 'audio', folder, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            print('file does not exist', path)\n",
    "            continue\n",
    "\n",
    "        sample, sr = librosa.load(path, 24000, duration=2)\n",
    "        assert sr == 24000, 'sample rate incorrect'\n",
    "\n",
    "        padded_sample = np.zeros(48001, dtype='float32')\n",
    "        padded_sample[:sample.shape[0]] = sample\n",
    "\n",
    "        melgram = librosa.feature.melspectrogram(padded_sample, sr, n_fft=512, hop_length=256, n_mels=96)\n",
    "        log_melgram = librosa.amplitude_to_db(melgram)\n",
    "        log_melgram = np.expand_dims(log_melgram, axis=-1)\n",
    "        assert log_melgram.shape == (96, 188, 1)\n",
    "\n",
    "        labels.append(row.label)\n",
    "        spectrums.append(log_melgram)\n",
    "\n",
    "        if index % 500 == 0:\n",
    "            print('loaded %d from %d rows' % (index, len(data)))\n",
    "        \n",
    "    x = np.stack(spectrums)\n",
    "    y = np.stack(labels)\n",
    "\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # shuffle\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "if os.path.isfile(DATASET_PATH):\n",
    "    print(\"loading from cache\")\n",
    "    with open(DATASET_PATH, 'rb') as handle:\n",
    "        train_x, train_y, test_x, test_y, val_x, val_y = pickle.load(handle)\n",
    "        print(train_x.shape, train_y.shape)\n",
    "\n",
    "else:        \n",
    "    train_x, train_y = preprocess(train, 'train')\n",
    "    test_x, test_y = preprocess(test, 'test')\n",
    "    val_x, val_y = preprocess(val, 'dev')\n",
    "    print(train_x.shape, train_y.shape)\n",
    "\n",
    "    with open(DATASET_PATH, 'wb') as handle:\n",
    "        pickle.dump((train_x, train_y, test_x, test_y, val_x, val_y), handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2637
    },
    "colab_type": "code",
    "id": "YLLqGOxg0xS_",
    "outputId": "0d654a5d-4ee5-4f8a-e0df-0073b8f0acbe"
   },
   "outputs": [],
   "source": [
    "# show some spectrograms\n",
    "for i in range(0, 10):\n",
    "    plt.imshow(np.squeeze(train_x[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "DWkp6RWt0xTC",
    "outputId": "20c18441-9769-4a96-e70c-a63a3422dd4a"
   },
   "outputs": [],
   "source": [
    "model_input = Input(shape=train_x.shape[1:])\n",
    "\n",
    "x = Conv2D(32, 5, activation='relu')(model_input)\n",
    "x = MaxPooling2D(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling2D(3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(model_input, x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10, verbose=1)\n",
    "print(\"Accuracy: %.2f\" % model.evaluate(test_x, test_y)[1])\n",
    "\n",
    "# base: 0.3417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "audio.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:event-acoustics]",
   "language": "python",
   "name": "conda-env-event-acoustics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
